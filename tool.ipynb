{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # 打印整个JSON结构\n",
    "    print(json.dumps(data, indent=4))\n",
    "\n",
    "    # 进行其他操作，例如提取特定字段、遍历数据等\n",
    "\n",
    "# 替换为你的JSON文件路径\n",
    "json_file_path = '/home/chenzhixuan/Workspace/R2Gen/data/iu_xray/annotation.json'\n",
    "\n",
    "parse_json_file(json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计数据集元素个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def count_elements_in_json(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        train_count = len(data['train'])\n",
    "        val_count = len(data['val'])\n",
    "        test_count = len(data['test'])\n",
    "    return train_count, val_count, test_count\n",
    "\n",
    "json_file_path = '/jhcnas1/chenzhixuan/mimic-cxr-jpg/annotation.json'\n",
    "train_count, val_count, test_count = count_elements_in_json(json_file_path)\n",
    "print('train_count: ', train_count)\n",
    "print('val_count: ', val_count)\n",
    "print('test_count: ', test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试DataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "# 1. 定义模型\n",
    "class Child_MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Child_MyModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.fc(x+y)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 2. 封装模型\n",
    "device_ids = [0, 1]  # 使用编号为 0 和 1 的 GPU 设备\n",
    "model = MyModel()\n",
    "model.cuda()\n",
    "model = DataParallel(model, device_ids=device_ids)\n",
    "\n",
    "# 4. 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 5. 训练模型\n",
    "for epoch in range(10):  # 迭代 10 次\n",
    "    for i in range(100):  # 每次迭代有 100 个批次\n",
    "        # 生成随机输入数据和标签\n",
    "        inputs = torch.randn(2, 3, 224, 224).to('cuda:0')  # 假设每个批次有 32 个样本，每个样本是 3x224x224 的图像\n",
    "        labels = torch.randn(2, 1000).to('cuda:0')  # 假设每个样本有 1000 个类别\n",
    "\n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 正向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "\n",
    "        # 更新权重\n",
    "        optimizer.step()\n",
    "\n",
    "        # 打印损失\n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Batch {i}, Loss: {loss.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenzhixuan/anaconda3/envs/r2gen/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/chenzhixuan/anaconda3/envs/r2gen/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenzhixuan/anaconda3/envs/r2gen/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/chenzhixuan/Workspace/R2Gen/tool.ipynb 单元格 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjhcpu1.cse.ust.hk/home/chenzhixuan/Workspace/R2Gen/tool.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjhcpu1.cse.ust.hk/home/chenzhixuan/Workspace/R2Gen/tool.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# 正向传播\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bjhcpu1.cse.ust.hk/home/chenzhixuan/Workspace/R2Gen/tool.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs, labels, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjhcpu1.cse.ust.hk/home/chenzhixuan/Workspace/R2Gen/tool.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# 计算损失\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjhcpu1.cse.ust.hk/home/chenzhixuan/Workspace/R2Gen/tool.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/anaconda3/envs/r2gen/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/r2gen/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/r2gen/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodule_kwargs[\u001b[39m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_apply(replicas, inputs, module_kwargs)\n\u001b[1;32m    186\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather(outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/r2gen/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparallel_apply\u001b[39m(\u001b[39mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mreturn\u001b[39;00m parallel_apply(replicas, inputs, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids[:\u001b[39mlen\u001b[39;49m(replicas)])\n",
      "File \u001b[0;32m~/anaconda3/envs/r2gen/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:102\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    100\u001b[0m         thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    101\u001b[0m     \u001b[39mfor\u001b[39;00m thread \u001b[39min\u001b[39;00m threads:\n\u001b[0;32m--> 102\u001b[0m         thread\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m    103\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     _worker(\u001b[39m0\u001b[39m, modules[\u001b[39m0\u001b[39m], inputs[\u001b[39m0\u001b[39m], kwargs_tup[\u001b[39m0\u001b[39m], devices[\u001b[39m0\u001b[39m], streams[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/r2gen/lib/python3.9/threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1061\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/r2gen/lib/python3.9/threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1081\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1082\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.r2gen import R2GenModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import argparse\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "\n",
    "# 2. 封装模型\n",
    "device_ids = [0, 1]  # 使用编号为 0 和 1 的 GPU 设备\n",
    "model = R2GenModel(0,0)\n",
    "model.cuda()\n",
    "model = DataParallel(model, device_ids=device_ids)\n",
    "\n",
    "# 4. 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 5. 训练模型\n",
    "for epoch in range(10):  # 迭代 10 次\n",
    "    for i in range(100):  # 每次迭代有 100 个批次\n",
    "        # 生成随机输入数据和标签\n",
    "        inputs = torch.randn(5, 2, 3, 224, 224).to('cuda:0')  # 假设每个批次有 32 个样本，每个样本是 3x224x224 的图像\n",
    "        labels = torch.randn(2, 1000).to('cuda:0')  # 假设每个样本有 1000 个类别\n",
    "\n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 正向传播\n",
    "        outputs = model(inputs, labels, mode='train')\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "\n",
    "        # 更新权重\n",
    "        optimizer.step()\n",
    "\n",
    "        # 打印损失\n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Batch {i}, Loss: {loss.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r2gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
